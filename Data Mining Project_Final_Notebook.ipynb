{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DNSC Data Mining Semester Project"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DonorsChoose.org Application Screening from Kaggle\n",
    "https://www.kaggle.com/c/donorschoose-application-screening"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Group Members:\n",
    "* Pei-Hsuan Hsia\n",
    "* Agnes Jiang\n",
    "* Guangyu Xing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import datetime as dt\n",
    "import numpy as np\n",
    "\n",
    "#LabelEncoder\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "#TD-IDF\n",
    "from tqdm import tqdm\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "#Models\n",
    "#from __future__ import division\n",
    "import lightgbm as lgb\n",
    "from sklearn import cross_validation, metrics\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "#RandomizedSearchCV, GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pd.set_option('display.max_columns', None) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\USER\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py:2698: DtypeWarning: Columns (11,12) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    }
   ],
   "source": [
    "train = pd.read_csv('D:\\\\2018Spring\\\\Data Mining\\\\final_project\\\\train.csv').fillna('')\n",
    "test = pd.read_csv('D:\\\\2018Spring\\\\Data Mining\\\\final_project\\\\test.csv').fillna('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['id', 'teacher_id', 'teacher_prefix', 'school_state',\n",
       "       'project_submitted_datetime', 'project_grade_category',\n",
       "       'project_subject_categories', 'project_subject_subcategories',\n",
       "       'project_title', 'project_essay_1', 'project_essay_2',\n",
       "       'project_essay_3', 'project_essay_4', 'project_resource_summary',\n",
       "       'teacher_number_of_previously_posted_projects', 'project_is_approved'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(182080, 16)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extracting information from Resource Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>description</th>\n",
       "      <th>quantity</th>\n",
       "      <th>price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>p233245</td>\n",
       "      <td>LC652 - Lakeshore Double-Space Mobile Drying Rack</td>\n",
       "      <td>1</td>\n",
       "      <td>149.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>p069063</td>\n",
       "      <td>Bouncy Bands for Desks (Blue support pipes)</td>\n",
       "      <td>3</td>\n",
       "      <td>14.95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>p069063</td>\n",
       "      <td>Cory Stories: A Kid's Book About Living With Adhd</td>\n",
       "      <td>1</td>\n",
       "      <td>8.45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>p069063</td>\n",
       "      <td>Dixon Ticonderoga Wood-Cased #2 HB Pencils, Bo...</td>\n",
       "      <td>2</td>\n",
       "      <td>13.59</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>p069063</td>\n",
       "      <td>EDUCATIONAL INSIGHTS FLUORESCENT LIGHT FILTERS...</td>\n",
       "      <td>3</td>\n",
       "      <td>24.95</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        id                                        description  quantity  \\\n",
       "0  p233245  LC652 - Lakeshore Double-Space Mobile Drying Rack         1   \n",
       "1  p069063        Bouncy Bands for Desks (Blue support pipes)         3   \n",
       "2  p069063  Cory Stories: A Kid's Book About Living With Adhd         1   \n",
       "3  p069063  Dixon Ticonderoga Wood-Cased #2 HB Pencils, Bo...         2   \n",
       "4  p069063  EDUCATIONAL INSIGHTS FLUORESCENT LIGHT FILTERS...         3   \n",
       "\n",
       "    price  \n",
       "0  149.00  \n",
       "1   14.95  \n",
       "2    8.45  \n",
       "3   13.59  \n",
       "4   24.95  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resource = pd.read_csv(\"D:\\\\2018Spring\\\\Data Mining\\\\final_project\\\\resources.csv\").fillna(' ')\n",
    "resource.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Aggregate and Merge\n",
    "resource['sum_price'] = resource['quantity'] * resource['price']\n",
    "agg_resource = resource.groupby(['id']).agg(\n",
    "    dict(quantity = ['sum',\"mean\"],\n",
    "         price = [\"max\",\"min\",\"std\"],\n",
    "         sum_price = [\"sum\"],\n",
    "         id = 'count',\n",
    "         description = lambda x: ' '.join(x))).reset_index()\n",
    "agg_resource.columns = pd.Index([e[0] +\"_\"+ e[1] for e in agg_resource.columns.tolist()]) # Collapse Multi-index\n",
    "agg_resource[\"price_avg\"] = round(agg_resource[\"sum_price_sum\"] / agg_resource[\"quantity_sum\"], 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "agg_resource.rename(columns = {'id_': \"id\", 'sum_price_sum':\"price_sum\", 'id_count':\"count\", 'description_<lambda>': \"description\"}, inplace=True)\n",
    "agg_resource.price_std.fillna(0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>quantity_sum</th>\n",
       "      <th>quantity_mean</th>\n",
       "      <th>price_max</th>\n",
       "      <th>price_min</th>\n",
       "      <th>price_std</th>\n",
       "      <th>price_sum</th>\n",
       "      <th>count</th>\n",
       "      <th>description</th>\n",
       "      <th>price_avg</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>p000001</td>\n",
       "      <td>7</td>\n",
       "      <td>1.750000</td>\n",
       "      <td>261.08</td>\n",
       "      <td>23.99</td>\n",
       "      <td>101.929679</td>\n",
       "      <td>833.63</td>\n",
       "      <td>4</td>\n",
       "      <td>Cap Barbell 300 Pound Olympic Set, Grey Cap Ba...</td>\n",
       "      <td>119.09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>p000002</td>\n",
       "      <td>21</td>\n",
       "      <td>1.500000</td>\n",
       "      <td>134.90</td>\n",
       "      <td>8.46</td>\n",
       "      <td>33.549557</td>\n",
       "      <td>630.28</td>\n",
       "      <td>14</td>\n",
       "      <td>10 Sony Headphones (BUY 9 GET 1 FREE) Belkin 6...</td>\n",
       "      <td>30.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>p000003</td>\n",
       "      <td>4</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>169.00</td>\n",
       "      <td>39.99</td>\n",
       "      <td>63.014906</td>\n",
       "      <td>298.97</td>\n",
       "      <td>4</td>\n",
       "      <td>EE820X - Phonemic Awareness Instant Learning C...</td>\n",
       "      <td>74.74</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>p000004</td>\n",
       "      <td>98</td>\n",
       "      <td>1.031579</td>\n",
       "      <td>401.54</td>\n",
       "      <td>1.60</td>\n",
       "      <td>40.608577</td>\n",
       "      <td>1126.22</td>\n",
       "      <td>95</td>\n",
       "      <td>A Bad Case of the Giggles Poems That Will Make...</td>\n",
       "      <td>11.49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>p000005</td>\n",
       "      <td>8</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>323.75</td>\n",
       "      <td>54.08</td>\n",
       "      <td>134.835000</td>\n",
       "      <td>702.31</td>\n",
       "      <td>4</td>\n",
       "      <td>Fitbit Zip Wireless Activity Tracker, Lime Fit...</td>\n",
       "      <td>87.79</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        id  quantity_sum  quantity_mean  price_max  price_min   price_std  \\\n",
       "0  p000001             7       1.750000     261.08      23.99  101.929679   \n",
       "1  p000002            21       1.500000     134.90       8.46   33.549557   \n",
       "2  p000003             4       1.000000     169.00      39.99   63.014906   \n",
       "3  p000004            98       1.031579     401.54       1.60   40.608577   \n",
       "4  p000005             8       2.000000     323.75      54.08  134.835000   \n",
       "\n",
       "   price_sum  count                                        description  \\\n",
       "0     833.63      4  Cap Barbell 300 Pound Olympic Set, Grey Cap Ba...   \n",
       "1     630.28     14  10 Sony Headphones (BUY 9 GET 1 FREE) Belkin 6...   \n",
       "2     298.97      4  EE820X - Phonemic Awareness Instant Learning C...   \n",
       "3    1126.22     95  A Bad Case of the Giggles Poems That Will Make...   \n",
       "4     702.31      4  Fitbit Zip Wireless Activity Tracker, Lime Fit...   \n",
       "\n",
       "   price_avg  \n",
       "0     119.09  \n",
       "1      30.01  \n",
       "2      74.74  \n",
       "3      11.49  \n",
       "4      87.79  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agg_resource.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Merge\n",
    "train1 = pd.merge(train, agg_resource, how = 'left', on = 'id')\n",
    "test1 = pd.merge(test, agg_resource, how = 'left', on = 'id')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate the approved rate within 7 days for every project submitted date - 'approve_rate_7d'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train['project_submitted_datetime'] = pd.to_datetime(train['project_submitted_datetime'])\n",
    "test['project_submitted_datetime'] = pd.to_datetime(test['project_submitted_datetime'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train1['date'] = train1['project_submitted_datetime'].dt.date\n",
    "test1['date'] = test1['project_submitted_datetime'].dt.date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "counts_submit = train1.groupby('date').size().reset_index(name = 'counts_submit')\n",
    "counts_approve = train1.loc[train1['project_is_approved'] == 1] \\\n",
    "                 .groupby('date').size().reset_index(name = 'counts_approve')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "counts_proposal = pd.merge(counts_submit, counts_approve, on = 'date')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "counts_proposal['time_range_end'] = counts_proposal['date']\n",
    "counts_proposal['time_range_start'] = counts_proposal['time_range_end'] - pd.to_timedelta(7, unit = 'D')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "counts_proposal['approve_rate_7d'] = \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 724 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "for i in range(counts_proposal.index.max()):\n",
    "    subset = counts_proposal.loc[(counts_proposal['date'] >= counts_proposal.loc[i, 'time_range_start']) \\\n",
    "                             & (counts_proposal['date'] <= counts_proposal.loc[i, 'time_range_end']), ['counts_submit','counts_approve']]\n",
    "    counts_proposal.loc[i, 'approve_rate_7d'] = subset['counts_approve'].sum() / subset['counts_submit'].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "counts_7d = counts_proposal[['date', 'approve_rate_7d']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train2 = pd.merge(train1, counts_7d, on = 'date')\n",
    "test2 = pd.merge(test1, counts_7d, on = 'date')\n",
    "train2.drop(['date'], axis = 1, inplace = True)\n",
    "test2.drop(['date'], axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Text counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train2[\"essays_combined\"] = train2[\"project_essay_1\"] + train2[\"project_essay_2\"]  \\\n",
    "                         + train2[\"project_essay_3\"] + train2[\"project_essay_4\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "text_col = [\"essays_combined\",\"project_resource_summary\", \"description\"]\n",
    "for col in text_col:\n",
    "    train2[col] = train2[col].astype(str)\n",
    "    train2[col] = train2[col].str.lower()\n",
    "    train2[col+'_n_chars'] = train2[col].apply(len) # Count number of Characters\n",
    "    train2[col+'_n_words'] = train2[col].apply(lambda x: len(x.split())) # Count number of Words\n",
    "    train2[col+'_n_uniq_words'] = train2[col].apply(lambda x: len(set(w for w in x.split()))) # Count Unique Words\n",
    "    train2[col+'_words_vs_unique'] = train2[col+'_n_uniq_words'] / train2[col+'_n_words']*100  # Unique words to Word count Ratio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train2.drop([\"project_essay_1\", \"project_essay_2\", \"project_essay_3\",\n",
    "              \"project_essay_4\"], inplace = True, axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "test2[\"essays_combined\"] = test2[\"project_essay_1\"] + test2[\"project_essay_2\"]  \\\n",
    "                         + test2[\"project_essay_3\"] + test2[\"project_essay_4\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for col in text_col:\n",
    "    test2[col] = test2[col].astype(str)\n",
    "    test2[col] = test2[col].str.lower()\n",
    "    test2[col+'_n_chars'] = test2[col].apply(len)\n",
    "    test2[col+'_n_words'] = test2[col].apply(lambda x: len(x.split()))\n",
    "    test2[col+'_n_uniq_words'] = test2[col].apply(lambda x: len(set(w for w in x.split())))\n",
    "    test2[col+'_words_vs_unique'] = test2[col+'_n_uniq_words'] / test2[col+'_n_words']*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test2.drop([\"project_essay_1\", \"project_essay_2\", \"project_essay_3\",\n",
    "              \"project_essay_4\"], inplace = True, axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Labor Encoding for Text Columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "encoding_col = [\"project_grade_category\", \"project_subject_categories\",\n",
    "             \"school_state\", \"teacher_prefix\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for col in encoding_col:\n",
    "    le = LabelEncoder()\n",
    "    le.fit(train2[col])\n",
    "    train2[col] = le.transform(train2[col])\n",
    "    test2[col] = le.transform(test2[col])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['id', 'teacher_id', 'teacher_prefix', 'school_state',\n",
       "       'project_submitted_datetime', 'project_grade_category',\n",
       "       'project_subject_categories', 'project_subject_subcategories',\n",
       "       'project_title', 'project_resource_summary',\n",
       "       'teacher_number_of_previously_posted_projects', 'project_is_approved',\n",
       "       'after_may2016', 'quantity_sum', 'quantity_mean', 'price_max',\n",
       "       'price_min', 'price_std', 'price_sum', 'count', 'description',\n",
       "       'price_avg', 'date', 'approve_rate_30d', 'essays_combined',\n",
       "       'essays_combined_n_chars', 'essays_combined_n_words',\n",
       "       'essays_combined_n_uniq_words', 'essays_combined_words_vs_unique',\n",
       "       'project_resource_summary_n_chars', 'project_resource_summary_n_words',\n",
       "       'project_resource_summary_n_uniq_words',\n",
       "       'project_resource_summary_words_vs_unique', 'description_n_chars',\n",
       "       'description_n_words', 'description_n_uniq_words',\n",
       "       'description_words_vs_unique'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train2.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sentiment analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "SIA = SentimentIntensityAnalyzer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dataset = [train2, test2]\n",
    "for data in dataset:\n",
    "    data['compound'] = 0\n",
    "    data['neg'] = 0\n",
    "    data['neu'] = 0\n",
    "    data['pos'] = 0\n",
    "    for i in range(data.shape[0]):\n",
    "        ss = SIA.polarity_scores(data.loc[i, 'essays_combined'])    \n",
    "        for k in sorted(ss):\n",
    "            data.loc[i, k] = ss[k]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#train2[['id,'compound','neg','neu','pos']].to_csv('train_sentiment.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#test2[['id','compound','neg','neu','pos']].to_csv('test_sentiment.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#train_sentiment = pd.read_csv('train_sentiment.csv')\n",
    "#test_sentiment = pd.read_csv('test_sentiment.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#train2 = pd.merge(train2, train_sentiment, on = 'id')\n",
    "#test2 = pd.merge(test2, test_sentiment, on = 'id')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preprocessing text...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "4it [12:02, 180.71s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 12min 2s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "cols = [\"essays_combined\", \"project_resource_summary\", \"project_title\", \"description\"]\n",
    "n_features = [10000, 1000, 400, 1000]\n",
    "\n",
    "for c_i, c in tqdm(enumerate(cols)):\n",
    "    tfidf = TfidfVectorizer(max_features=n_features[c_i], min_df=3)\n",
    "    tfidf.fit(train2[c])\n",
    "    tfidf_train = np.array(tfidf.transform(train2[c]).todense(), dtype=np.float16)\n",
    "    tfidf_test = np.array(tfidf.transform(test2[c]).todense(), dtype=np.float16)\n",
    "\n",
    "    for i in range(n_features[c_i]):\n",
    "        train2[c + '_tfidf_' + str(i)] = tfidf_train[:, i]\n",
    "        test2[c + '_tfidf_' + str(i)] = tfidf_test[:, i]        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(182080, 12437)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train2.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Models: LGBM + Logistics Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Light GBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_model = train2.drop(['id', 'project_submitted_datetime', 'approve_rate_30d', 'teacher_id', 'project_subject_subcategories',\n",
    "       'project_title', 'project_resource_summary', 'description','essays_combined', \"project_is_approved\"], axis = 1)\n",
    "test_model = test2.drop(['id', 'project_submitted_datetime', 'approve_rate_30d','teacher_id', 'project_subject_subcategories',\n",
    "       'project_title', 'project_resource_summary', 'description','essays_combined'], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y = train2[\"project_is_approved\"].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train, X_valid, y_train, y_valid = train_test_split(train_model, y, test_size=0.3, random_state=23)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lgb_train = lgb.Dataset(X_train, y_train)\n",
    "lgb_eval = lgb.Dataset(X_valid, y_valid, reference=lgb_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "params = {'task': 'train', 'boosting_type': 'gbdt', 'objective': 'binary', 'metric': {'binary_logloss'}, 'num_leaves': 63,\n",
    "          'num_trees': 100, 'learning_rate': 0.01, 'feature_fraction': 0.9, 'bagging_fraction': 0.8, 'bagging_freq': 5,\n",
    "          'verbose': 0}\n",
    "num_leaf = 63"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\USER\\Anaconda3\\lib\\site-packages\\lightgbm\\engine.py:99: UserWarning: Found `num_trees` in params. Will use it instead of argument\n",
      "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1]\tvalid_0's binary_logloss: 0.687901\n",
      "[2]\tvalid_0's binary_logloss: 0.682736\n",
      "[3]\tvalid_0's binary_logloss: 0.677664\n",
      "[4]\tvalid_0's binary_logloss: 0.672676\n",
      "[5]\tvalid_0's binary_logloss: 0.667809\n",
      "[6]\tvalid_0's binary_logloss: 0.663054\n",
      "[7]\tvalid_0's binary_logloss: 0.658368\n",
      "[8]\tvalid_0's binary_logloss: 0.653776\n",
      "[9]\tvalid_0's binary_logloss: 0.649285\n",
      "[10]\tvalid_0's binary_logloss: 0.644851\n",
      "[11]\tvalid_0's binary_logloss: 0.640521\n",
      "[12]\tvalid_0's binary_logloss: 0.636277\n",
      "[13]\tvalid_0's binary_logloss: 0.632105\n",
      "[14]\tvalid_0's binary_logloss: 0.628032\n",
      "[15]\tvalid_0's binary_logloss: 0.623999\n",
      "[16]\tvalid_0's binary_logloss: 0.620046\n",
      "[17]\tvalid_0's binary_logloss: 0.616165\n",
      "[18]\tvalid_0's binary_logloss: 0.612363\n",
      "[19]\tvalid_0's binary_logloss: 0.608624\n",
      "[20]\tvalid_0's binary_logloss: 0.604952\n",
      "[21]\tvalid_0's binary_logloss: 0.601337\n",
      "[22]\tvalid_0's binary_logloss: 0.597781\n",
      "[23]\tvalid_0's binary_logloss: 0.5943\n",
      "[24]\tvalid_0's binary_logloss: 0.590877\n",
      "[25]\tvalid_0's binary_logloss: 0.587507\n",
      "[26]\tvalid_0's binary_logloss: 0.584215\n",
      "[27]\tvalid_0's binary_logloss: 0.580978\n",
      "[28]\tvalid_0's binary_logloss: 0.577787\n",
      "[29]\tvalid_0's binary_logloss: 0.574654\n",
      "[30]\tvalid_0's binary_logloss: 0.57158\n",
      "[31]\tvalid_0's binary_logloss: 0.568559\n",
      "[32]\tvalid_0's binary_logloss: 0.565589\n",
      "[33]\tvalid_0's binary_logloss: 0.562674\n",
      "[34]\tvalid_0's binary_logloss: 0.559802\n",
      "[35]\tvalid_0's binary_logloss: 0.556978\n",
      "[36]\tvalid_0's binary_logloss: 0.55418\n",
      "[37]\tvalid_0's binary_logloss: 0.551434\n",
      "[38]\tvalid_0's binary_logloss: 0.548744\n",
      "[39]\tvalid_0's binary_logloss: 0.5461\n",
      "[40]\tvalid_0's binary_logloss: 0.54348\n",
      "[41]\tvalid_0's binary_logloss: 0.54092\n",
      "[42]\tvalid_0's binary_logloss: 0.53839\n",
      "[43]\tvalid_0's binary_logloss: 0.535894\n",
      "[44]\tvalid_0's binary_logloss: 0.53344\n",
      "[45]\tvalid_0's binary_logloss: 0.531034\n",
      "[46]\tvalid_0's binary_logloss: 0.528673\n",
      "[47]\tvalid_0's binary_logloss: 0.526355\n",
      "[48]\tvalid_0's binary_logloss: 0.524067\n",
      "[49]\tvalid_0's binary_logloss: 0.521821\n",
      "[50]\tvalid_0's binary_logloss: 0.519619\n",
      "[51]\tvalid_0's binary_logloss: 0.517442\n",
      "[52]\tvalid_0's binary_logloss: 0.515297\n",
      "[53]\tvalid_0's binary_logloss: 0.513188\n",
      "[54]\tvalid_0's binary_logloss: 0.511105\n",
      "[55]\tvalid_0's binary_logloss: 0.509054\n",
      "[56]\tvalid_0's binary_logloss: 0.507045\n",
      "[57]\tvalid_0's binary_logloss: 0.505049\n",
      "[58]\tvalid_0's binary_logloss: 0.503094\n",
      "[59]\tvalid_0's binary_logloss: 0.501169\n",
      "[60]\tvalid_0's binary_logloss: 0.499282\n",
      "[61]\tvalid_0's binary_logloss: 0.497427\n",
      "[62]\tvalid_0's binary_logloss: 0.495597\n",
      "[63]\tvalid_0's binary_logloss: 0.4938\n",
      "[64]\tvalid_0's binary_logloss: 0.492031\n",
      "[65]\tvalid_0's binary_logloss: 0.490292\n",
      "[66]\tvalid_0's binary_logloss: 0.488582\n",
      "[67]\tvalid_0's binary_logloss: 0.486894\n",
      "[68]\tvalid_0's binary_logloss: 0.485232\n",
      "[69]\tvalid_0's binary_logloss: 0.483587\n",
      "[70]\tvalid_0's binary_logloss: 0.481979\n",
      "[71]\tvalid_0's binary_logloss: 0.480384\n",
      "[72]\tvalid_0's binary_logloss: 0.478836\n",
      "[73]\tvalid_0's binary_logloss: 0.477299\n",
      "[74]\tvalid_0's binary_logloss: 0.475782\n",
      "[75]\tvalid_0's binary_logloss: 0.474293\n",
      "[76]\tvalid_0's binary_logloss: 0.472825\n",
      "[77]\tvalid_0's binary_logloss: 0.471375\n",
      "[78]\tvalid_0's binary_logloss: 0.469951\n",
      "[79]\tvalid_0's binary_logloss: 0.46855\n",
      "[80]\tvalid_0's binary_logloss: 0.467163\n",
      "[81]\tvalid_0's binary_logloss: 0.465798\n",
      "[82]\tvalid_0's binary_logloss: 0.464455\n",
      "[83]\tvalid_0's binary_logloss: 0.463123\n",
      "[84]\tvalid_0's binary_logloss: 0.461818\n",
      "[85]\tvalid_0's binary_logloss: 0.460532\n",
      "[86]\tvalid_0's binary_logloss: 0.459281\n",
      "[87]\tvalid_0's binary_logloss: 0.458043\n",
      "[88]\tvalid_0's binary_logloss: 0.456828\n",
      "[89]\tvalid_0's binary_logloss: 0.455629\n",
      "[90]\tvalid_0's binary_logloss: 0.454451\n",
      "[91]\tvalid_0's binary_logloss: 0.45328\n",
      "[92]\tvalid_0's binary_logloss: 0.452139\n",
      "[93]\tvalid_0's binary_logloss: 0.451008\n",
      "[94]\tvalid_0's binary_logloss: 0.449887\n",
      "[95]\tvalid_0's binary_logloss: 0.448795\n",
      "[96]\tvalid_0's binary_logloss: 0.447735\n",
      "[97]\tvalid_0's binary_logloss: 0.446677\n",
      "[98]\tvalid_0's binary_logloss: 0.445635\n",
      "[99]\tvalid_0's binary_logloss: 0.444601\n",
      "[100]\tvalid_0's binary_logloss: 0.443579\n",
      "Wall time: 5min 40s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "gbm = lgb.train(params, lgb_train, num_boost_round = 100, valid_sets = lgb_eval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_pred = gbm.predict(X_train,pred_leaf=True)\n",
    "y_pred_valid = gbm.predict(X_valid,pred_leaf=True)\n",
    "y_pred_test = gbm.predict(test_model,pred_leaf=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "transformed_training_matrix = np.zeros([len(y_pred),len(y_pred[0]) * num_leaf],dtype=np.int64)\n",
    "for i in range(0, len(y_pred)):\n",
    "    temp = np.arange(len(y_pred[0])) * num_leaf - 1 + np.array(y_pred[i])\n",
    "    transformed_training_matrix[i][temp] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "transformed_training_matrix_valid = np.zeros([len(y_pred_valid),len(y_pred_valid[0]) * num_leaf],dtype=np.int64)\n",
    "for i in range(0, len(y_pred_valid)):\n",
    "    temp = np.arange(len(y_pred_valid[0])) * num_leaf - 1 + np.array(y_pred_valid[i])\n",
    "    transformed_training_matrix_valid[i][temp] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "transformed_training_matrix_test = np.zeros([len(y_pred_test),len(y_pred_test[0]) * num_leaf],dtype=np.int64)\n",
    "for i in range(0, len(y_pred_test)):\n",
    "    temp = np.arange(len(y_pred_test[0])) * num_leaf - 1 + np.array(y_pred_test[i])\n",
    "    transformed_training_matrix_test[i][temp] += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Logistics Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "c = np.array([1,0.5,0.1,0.05,0.01,0.005,0.001])\n",
    "for t in range(0,len(c)):\n",
    "    lm = LogisticRegression(penalty='l2',C=c[t]) # logestic model construction\n",
    "    lm.fit(transformed_training_matrix, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 3.48 s\n"
     ]
    }
   ],
   "source": [
    "y_pred_est = lm.predict_proba(transformed_training_matrix)\n",
    "y_pred_est_valid = lm.predict_proba(transformed_training_matrix_valid)\n",
    "y_pred_est_test = lm.predict_proba(transformed_training_matrix_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pred = pd.DataFrame(y_pred_est)\n",
    "pred_train = pred[1]\n",
    "\n",
    "pred = pd.DataFrame(y_pred_est_valid)\n",
    "pred_valid = pred[1]\n",
    "\n",
    "pred = pd.DataFrame(y_pred_est_test)\n",
    "pred_test = pred[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.77931377370002053"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_auc = metrics.roc_auc_score(y_train, pred_train)\n",
    "train_auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.74393439277053186"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "valid_auc = metrics.roc_auc_score(y_valid, pred_valid)\n",
    "valid_auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "submission = pd.DataFrame()\n",
    "submission['id'] = test2['id']\n",
    "submission['project_is_approved'] = pred_test\n",
    "submission = submission.set_index('id')\n",
    "submission.to_csv('submission.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
